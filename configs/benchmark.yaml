# Full benchmark configuration
project: "meta-feature-matching"
run_name: "full_benchmark"

# Logging
use_wandb: true

hpatches_root: "/Data/adrian.garcia/hpatches/hpatches"

# Which evaluations to run
eval_traditional: true   # SIFT, ORB, BRISK, AKAZE
eval_deep: true          # Deep learning descriptors
eval_continual: true     # Continual learning methods
eval_maml: true          # MAML meta-learning

# Model configurations
deep_models:
  - "resnet50"
  - "resnet18"
  - "lightweight"
  - "hardnet"

# Continual learning methods to compare
continual_methods:
  - "naive"     # No forgetting prevention
  - "ewc"       # Elastic Weight Consolidation
  - "lwf"       # Learning without Forgetting
  - "si"        # Synaptic Intelligence

# Training hyperparameters
batch_size: 32
lr: 1.0e-4

# Epochs for each phase
deep_epochs: 15          # Epochs for training deep models
epochs_source: 15        # Epochs on source domain
epochs_target: 15        # Epochs on target domain  
meta_epochs: 10          # Meta-learning epochs

# MAML specific
meta_lr_inner: 1.0e-3    # Inner loop learning rate
meta_lr_outer: 1.0e-4    # Outer loop learning rate
num_inner_steps: 3       # Inner loop steps

# EWC specific
ewc_lambda: 1000.0

# LwF specific
lwf_lambda: 1.0
lwf_temperature: 2.0

# SI specific
si_lambda: 1.0

# Evaluation
mma_thresholds: [1, 3, 5, 10]
adaptation_steps: [0, 1, 2, 5, 10, 20]
